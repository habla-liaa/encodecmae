### EnCodecMAE: Leveraging neural codecs for universal audio representation learning

<p align="center">
    <a href="http://arxiv.org/abs/2309.07391">
        <img alt="read the paper" src="https://img.shields.io/badge/Read_the_paper-2ea44f">
    </a>
    <a href="https://colab.research.google.com/drive/123Zn6h0DRVcjsLFp8Xl4j0PZlZ-7VsK2?usp=sharing">
        <img alt="run in colab" src="https://colab.research.google.com/assets/colab-badge.svg">
    </a>
    <a href="https://"><img src="https://img.shields.io/badge/Cite-Bibtex-2ea44f" alt="Cite - Bibtex"></a>
</p>

This is EnCodecMAE, an audio feature extractor pretrained with masked language modelling to predict discrete targets generated by EnCodec, a neural audio codec. 
For more details about the architecture and pretraining procedure, read the [paper](https://arxiv.org/abs/2309.07391).

# Usage

### Try our example [Colab notebook](https://colab.research.google.com/drive/123Zn6h0DRVcjsLFp8Xl4j0PZlZ-7VsK2?usp=sharing) or

### 1) Clone the [EnCodecMAE library](https://github.com/habla-liaa/encodecmae):
```
git clone https://github.com/habla-liaa/encodecmae.git
```

### 2) Install it:

```
cd encodecmae
pip install -e .
```

### 3) Extract embeddings in Python:

``` python
from encodecmae import load_model

model = load_model('base', device='cuda:0')
features = model.extract_features_from_file('gsc/bed/00176480_nohash_0.wav')
```
