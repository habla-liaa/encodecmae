NUM_ENCODEC_TARGETS=8
NUM_TOTAL_TARGETS=8
NUM_TARGET_TOKENS=1024
MASK_GAP_SIZE=15
MASK_PROP=0.5
MODEL_DIM=768
NUM_ENCODER_LAYERS=10
NUM_ENCODER_HEADS=12
NUM_DECODER_LAYERS=2
NUM_DECODER_HEADS=12
MASKED_LOSS_WEIGHT=0.9
WAV_FEATURE_DIM=128
QUANTIZER_WEIGHTS=[0.22407463, 0.1759858 , 0.14499009, 0.12150037, 0.10315603, 0.08831368, 0.07608274, 0.06589669]
RETURN_ONLY_LAST_Q=False

#Global settings:
encodecmae.tasks.fit_model.model_cls=@encodecmae.models.EncodecMAE
encodecmae.models.EncodecMAE:
    wav_encoder = @encodecmae.models.encoders.WavEncoder
    target_encoder = @encodecmae.models.targets.EncodecQuantizer
    masker = @encodecmae.models.masks.PatchoutMask
    visible_encoder = @encoder/encodecmae.models.transformers.TransformerEncoder
    decoder = @decoder/encodecmae.models.transformers.TransformerEncoder
    head = @encodecmae.models.heads.FrameLevelClassificationHead
    loss = @encodecmae.models.losses.EnCodecMAEClassificationLoss
    optimizer=@torch.optim.AdamW

#Wav encoder:
encodecmae.models.encoders.WavEncoder:
    encoder = @encodecmae.models.encoders.EncodecEncoder
    post_net = @wav_encoder_proj/torch.nn.Linear
wav_encoder_proj/torch.nn.Linear:
    in_features = %WAV_FEATURE_DIM
    out_features = %MODEL_DIM

#Masking:
encodecmae.models.masks.PatchoutMask:
    masker = @encodecmae.models.masks.TimeGapMask
    positional_encoder = @encodecmae.models.transformers.SinusoidalPositionalEmbeddings
encodecmae.models.masks.TimeGapMask:
    gap_size = %MASK_GAP_SIZE
    p_mask = %MASK_PROP

#Visible encoder:
encoder/encodecmae.models.transformers.TransformerEncoder:
    model_dim=%MODEL_DIM
    num_layers=%NUM_ENCODER_LAYERS
    attention_layer=@encoder/encodecmae.models.transformers.MultiHeadAttention
    compile=False
    key_in='visible_tokens'
    key_padding_mask='visible_padding_mask'
    key_out='decoder_in'
    key_transformer_in=None
    key_transformer_out='visible_embeddings'
    post_net=@decoder_proj/torch.nn.Linear
encoder/encodecmae.models.transformers.MultiHeadAttention:
    model_dim=%MODEL_DIM
    num_heads=%NUM_ENCODER_HEADS

#Decoder:
decoder_proj/torch.nn.Linear:
    in_features=%MODEL_DIM
    out_features=%MODEL_DIM
decoder/encodecmae.models.transformers.TransformerEncoder:
    model_dim=%MODEL_DIM
    num_layers=%NUM_DECODER_LAYERS
    attention_layer=@decoder/encodecmae.models.transformers.MultiHeadAttention
    compile=False
    key_in='decoder_in'
    key_padding_mask='feature_padding_mask'
    key_out='decoder_out'
    positional_encoder = @encodecmae.models.transformers.SinusoidalPositionalEmbeddings
decoder/encodecmae.models.transformers.MultiHeadAttention:
    model_dim=%MODEL_DIM
    num_heads=%NUM_DECODER_HEADS

encodecmae.models.transformers.SinusoidalPositionalEmbeddings.embedding_dim = %MODEL_DIM

#Head:
encodecmae.models.heads.FrameLevelClassificationHead:
    model_dim=%MODEL_DIM
    num_tokens=%NUM_TARGET_TOKENS
    num_streams=%NUM_TOTAL_TARGETS
#Target:
encodecmae.models.targets.EncodecQuantizer:
    n = %NUM_ENCODEC_TARGETS
    key_in = 'wav_features_encoder_out'
    return_only_last = %RETURN_ONLY_LAST_Q
#Loss:
encodecmae.models.losses.EnCodecMAEClassificationLoss:
    masked_weight=%MASKED_LOSS_WEIGHT
    quantizer_weights=%QUANTIZER_WEIGHTS
#Optimizer:
torch.optim.AdamW:
    lr=%MAX_LR
    betas=(0.9,0.95)
    weight_decay=0.05